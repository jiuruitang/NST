# -*- coding: utf-8 -*-
"""590final_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Gbc71TxN74dXYiARaqdNT_b3o-2AorBj
"""

# Commented out IPython magic to ensure Python compatibility.
# %pylab inline
image_dir = '/content/drive/MyDrive/Images/'
# model_dir = os.getcwd() + '/Models/'

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch import optim

import torchvision
from torchvision import transforms
import torchvision.models as models

from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

image_dir = '/content/drive/MyDrive/Images/'

device = "cuda" if torch.cuda.is_available() else "cpu"
if device =='cuda':
    print('Training on GPU......')
else: 
    print('Training on CPU......')

# load image
def import_img(image_name,w = 500, h = 400):
  image_dir = '/content/drive/MyDrive/Images/'
  image = Image.open(image_dir+image_name).convert('RGB')  

  # transformations
  image_trans = transforms.Compose([transforms.Resize((h, w)),
                                    transforms.ToTensor(),
                                    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225)) #imagenet mean and std
  ])
  image = image_trans(image).unsqueeze(0) # get 4D tensor

  return image

# this function does image post-processing
def export_img(tensor):
  image = tensor.clone().detach().cpu().numpy().squeeze()
  image = image.transpose(1, 2, 0)
  image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))
  image = image.clip(0, 1)  

  return image

# load content and style images
content = torch.tensor(import_img('Tuebingen_Neckarfront.jpg')).to(device)
style = torch.tensor(import_img('Composition7.jpeg')).to(device)

# load pre-trained vgg 19
net = models.vgg19(pretrained=True).features

# average pooling 
for n, layer in net.named_children():
  if isinstance(layer, torch.nn.MaxPool2d):
    net[int(n)] = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)


for param in net.parameters():
  param.requires_grad_(False)
    
net.to(device)

# grasp desired features from vgg 
def get_features(image, model):
  layers = {'0': 'conv1_1', '5': 'conv2_1', '10': 'conv3_1', '19': 'conv4_1', '21': 'conv4_2', '28': 'conv5_1'}
        
  features = {} 
  x = image
  for name, layer in model._modules.items():
      x = layer(x)
      if name in layers:
          features[layers[name]] = x
            
  return features

# MSE 
def calc_MSE(tensor1, tensor2):
  return torch.sum((tensor1 - tensor2) ** 2)/2

# Gram matrix for style representation
def Gram_matrix(tensor):
  # get dimension
  n, c, h, w = tensor.shape
  tensor = tensor.view(c, h * w)
  gram = torch.mm(tensor, tensor.t())

  return gram

target = content.clone().requires_grad_(True)

style_weights = {'conv1_1': 0.2,
                 'conv2_1': 0.2,
                 'conv3_1': 0.2,
                 'conv4_1': 0.2,
                 'conv5_1': 0.2}

optimizer = optim.Adam([target], lr=0.01)

total_loss_track = []

# get features from content and style, they never change
content_features = get_features(content, net)
style_features = get_features(style, net)

# sweep of hyperparameter
alpha = 1
beta = 1e3

niter = 5000

for i in range(niter):
  optimizer.zero_grad()
  
  # get target features in each iteration, this is where gradient descent happens
  target_features = get_features(target, net)
  
  content_loss = calc_MSE(target_features['conv4_2'],content_features['conv4_2'])
    
  style_loss = 0
  for layer in style_weights:
      n, c, h, w = target_features[layer].shape
      m = h*w  
       
      # gram matrices
      G = Gram_matrix(target_features[layer])
      A = Gram_matrix(style_features[layer]) 
      style_loss += style_weights[layer] * calc_MSE(G,A)/ (4 * n**2 * m**2) 
             
  total_loss = alpha * content_loss + beta * style_loss
    
  total_loss.backward()
  optimizer.step()
  total_loss_track = total_loss_track + [total_loss]

fig, ax = plt.subplots(1, 1,dpi = 100)
ax.imshow(export_img(target))
plt.axis('off')
plt.show()

plt.plot(total_loss_track)